#!/usr/bin/env python3
"""
ä¸­ç¾å…³ç³»ä¸“é¢˜æ–°é—» Telegram Bot
"""

import os
import sys
import requests
import xml.etree.ElementTree as ET
import time
import random
import json
import re
from datetime import datetime, timedelta
from dotenv import load_dotenv
import google.generativeai as genai

load_dotenv()

def log(message):
    """ç»Ÿä¸€æ—¥å¿—è¾“å‡º"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print(f"[{timestamp}] {message}")

def get_beijing_timestamp():
    """è·å–åŒ—äº¬æ—¶é—´æˆ³"""
    utc_now = datetime.utcnow()
    beijing_time = utc_now + timedelta(hours=8)
    return beijing_time.strftime("%Y-%m-%d %H:%M")

def setup_gemini():
    """è®¾ç½® Gemini API"""
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        log("âš ï¸ æœªè®¾ç½® GEMINI_API_KEYï¼Œå°†ä½¿ç”¨åŸºç¡€åŠŸèƒ½")
        return None
    
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5-flash')
        log("âœ… Gemini API é…ç½®æˆåŠŸ")
        return model
    except Exception as e:
        log(f"âŒ Gemini API é…ç½®å¤±è´¥: {e}")
        return None

def escape_html(text: str) -> str:
    """è½¬ä¹‰ Telegram HTML æ¨¡å¼éœ€è¦çš„å­—ç¬¦"""
    if not text:
        return ""
    return (
        text.replace("&", "&amp;")
            .replace("<", "&lt;")
            .replace(">", "&gt;")
    )

def sanitize_text(text: str) -> str:
    """ç§»é™¤æ— å…³ç¬¦å·"""
    if not text:
        return ""
    cleaned = text.replace("*", "").replace("`", "")
    cleaned = cleaned.strip('"').strip("'")
    cleaned = cleaned.replace("\\n", " ").replace("\n", " ")
    while "  " in cleaned:
        cleaned = cleaned.replace("  ", " ")
    return cleaned.strip()

def clean_ai_artifacts(text: str) -> str:
    """æ¸…ç† AI è¾“å‡ºä¸­çš„è¯´æ˜æ€§å‰ç¼€/å™ªå£°"""
    if not text:
        return ""
    cleaned = text
    patterns = [
        r"^ä»¥ä¸‹æ˜¯.*?ä¸­æ–‡ç¿»è¯‘[:ï¼š]\s*",
        r"^ç¿»è¯‘[ä¸€äºŒä¸‰]?[ï¼š:]\s*",
        r"^è§£é‡Š[ï¼š:]\s*.*$",
        r"^æˆ–[è€…]?[ï¼š:]\s*",
        r"^æ³¨[ï¼š:]\s*",
    ]
    for p in patterns:
        cleaned = re.sub(p, "", cleaned, flags=re.IGNORECASE|re.MULTILINE)
    cleaned = re.sub(r"ï¼ˆ[^ï¼‰]*?(è¯·åˆ é™¤|ä¸éœ€è¦|è§£é‡Š|ç¤ºä¾‹)[^ï¼‰]*?ï¼‰", "", cleaned)
    cleaned = re.sub(r"\([^)]*?(please remove|example|explanation)[^)]*?\)", "", cleaned, flags=re.IGNORECASE)
    cleaned = sanitize_text(cleaned)
    return cleaned

def summarize_text(model, title: str, content: str, fallback_chars: int = 90) -> str:
    """ç”Ÿæˆç®€çŸ­æ‘˜è¦"""
    raw = (content or "")
    if not raw and title:
        raw = title
    if model:
        try:
            prompt = f"è¯·ç”¨ç®€ä½“ä¸­æ–‡å°†ä»¥ä¸‹æ–°é—»æ¦‚è¿°ä¸ºæœ€å¤š60å­—ï¼Œä¿ç•™å…³é”®ä¿¡æ¯ï¼Œä¸è¦åŠ å‰åç¼€ï¼š\næ ‡é¢˜ï¼š{title}\nå†…å®¹ï¼š{content}"
            resp = model.generate_content(prompt)
            summary = (resp.text or "").strip()
            summary = summary.strip('"').strip("'")
            if len(summary) > 60:
                summary = summary[:57] + "..."
            return summary
        except Exception:
            pass
    clean = raw.replace("\n", " ").strip()
    if len(clean) > fallback_chars:
        return clean[:fallback_chars - 3] + "..."
    return clean

def translate_with_gemini(model, text):
    """ä½¿ç”¨ Gemini ç¿»è¯‘æ–‡æœ¬"""
    if not model:
        return text
    
    try:
        prompt = f"è¯·å°†ä»¥ä¸‹è‹±æ–‡æ–°é—»ç¿»è¯‘æˆä¸­æ–‡ï¼Œä¿æŒä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§ï¼š\n\n{text}"
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        log(f"âš ï¸ ç¿»è¯‘å¤±è´¥: {e}")
        return text

def fetch_gnews_china_us(api_key, max_articles=8):
    """ä» GNews API è·å–ä¸­ç¾å…³ç³»æ–°é—»"""
    log("ğŸ“¡ è·å–ä¸­ç¾å…³ç³»æ–°é—»...")
    
    try:
        # æœç´¢ä¸­ç¾å…³ç³»ç›¸å…³å…³é”®è¯
        search_queries = [
            "China US relations",
            "China trade war",
            "China tariffs",
            "China technology ban",
            "China congress bill",
            "China policy",
            "China investment",
            "China semiconductor"
        ]
        
        all_articles = []
        
        for query in search_queries:
            url = "https://gnews.io/api/v4/search"
            params = {
                'token': api_key,
                'q': query,
                'lang': 'en',
                'country': 'us',
                'max': 2
            }
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, params=params, headers=headers, timeout=15)
            
            if response.status_code == 200:
                data = response.json()
                articles = data.get('articles', [])
                
                for article in articles:
                    all_articles.append({
                        'title': article.get('title', ''),
                        'content': article.get('description', ''),
                        'source': article.get('source', {}).get('name', 'GNews'),
                        'time': article.get('publishedAt', ''),
                        'url': article.get('url', ''),
                        'type': 'gnews'
                    })
            
            time.sleep(1)  # é¿å… API é™åˆ¶
        
        # å»é‡
        seen_titles = set()
        unique_articles = []
        for article in all_articles:
            title = article.get('title', '').lower()
            if title not in seen_titles and len(title) > 10:
                seen_titles.add(title)
                unique_articles.append(article)
        
        log(f"âœ… GNews ä¸­ç¾å…³ç³»: {len(unique_articles)} æ¡æ–°é—»")
        return unique_articles[:max_articles]
        
    except Exception as e:
        log(f"âŒ GNews ä¸­ç¾å…³ç³»è·å–å¤±è´¥: {e}")
        return []

def fetch_rss_china_us():
    """è·å– RSS ä¸­ç¾å…³ç³»æ–°é—»"""
    log("ğŸ“¡ è·å– RSS ä¸­ç¾å…³ç³»æ–°é—»...")
    
    rss_sources = [
        ("NPR News", "http://www.npr.org/rss/rss.php?id=1001"),
        ("HuffPost World", "https://www.huffpost.com/section/world-news/feed"),
        ("FOX News", "http://feeds.foxnews.com/foxnews/latest"),
        ("NYT Top Stories", "https://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml"),
        ("CNN International", "http://rss.cnn.com/rss/edition.rss"),
        ("Bloomberg", "https://feeds.bloomberg.com/markets/news.rss"),
    ]
    
    all_news = []
    
    # ä¸­ç¾å…³ç³»å…³é”®è¯
    china_us_keywords = [
        'china', 'chinese', 'beijing', 'beijing', 'taiwan', 'taiwanese',
        'trade war', 'tariff', 'semiconductor', 'chip', 'huawei', 'tiktok',
        'congress', 'senate', 'house', 'bill', 'proposal', 'legislation',
        'biden china', 'trump china', 'us china', 'america china',
        'investment', 'sanction', 'export', 'import', 'manufacturing',
        'technology', 'ai', 'artificial intelligence', '5g', 'cyber',
        'military', 'defense', 'navy', 'air force', 'pacific'
    ]
    
    for name, url in rss_sources:
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': 'application/rss+xml, application/xml, text/xml, */*',
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                root = ET.fromstring(response.text)
                items = root.findall('.//item')
                
                for item in items[:5]:  # æ¯ä¸ªæºæœ€å¤š5æ¡
                    title_elem = item.find('title')
                    link_elem = item.find('link')
                    description_elem = item.find('description')
                    pub_date_elem = item.find('pubDate')
                    
                    if title_elem is not None and link_elem is not None:
                        title = title_elem.text
                        link = link_elem.text
                        description = description_elem.text if description_elem is not None else ""
                        pub_date = pub_date_elem.text if pub_date_elem is not None else ""
                        
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­ç¾å…³ç³»å…³é”®è¯
                        content = f"{title} {description}".lower()
                        
                        if any(keyword.lower() in content for keyword in china_us_keywords):
                            all_news.append({
                                'title': title,
                                'content': description,
                                'source': name,
                                'time': pub_date,
                                'url': link,
                                'type': 'rss'
                            })
            
            time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
            
        except Exception as e:
            log(f"âŒ {name}: {e}")
    
    log(f"ğŸ“Š RSS ä¸­ç¾å…³ç³»: {len(all_news)} æ¡æ–°é—»")
    return all_news

def search_china_us_with_gemini(model):
    """ä½¿ç”¨ Gemini æœç´¢ä¸­ç¾å…³ç³»æ–°é—»"""
    if not model:
        return []
    
    search_queries = [
        "China US trade relations latest news",
        "US Congress China bills proposals 2025",
        "China technology restrictions US policy",
        "China Taiwan relations US stance",
        "China semiconductor ban US companies",
        "China investment restrictions US",
        "China military tensions US response"
    ]
    
    all_news = []
    
    for query in search_queries:
        try:
            log(f"ğŸ” Gemini æœç´¢: {query}")
            
            prompt = f"""
            è¯·æœç´¢å…³äº"{query}"çš„æœ€æ–°æ–°é—»ï¼Œé‡ç‚¹å…³æ³¨ï¼š
            1. ç¾å›½å›½ä¼šè®®å‘˜çš„æ–°ææ¡ˆ
            2. ä¸­ç¾è´¸æ˜“æ”¿ç­–å˜åŒ–
            3. æŠ€æœ¯é™åˆ¶å’Œåˆ¶è£
            4. å°æ¹¾é—®é¢˜ç›¸å…³åŠ¨æ€
            5. å†›äº‹å’Œå¤–äº¤æ”¿ç­–
            
            è¯·æä¾› 2 æ¡æœ€é‡è¦çš„æ–°é—»ï¼Œæ¯æ¡åŒ…å«ï¼š
            - æ ‡é¢˜
            - ç®€è¦å†…å®¹
            - æ¥æº
            - æ—¶é—´
            
            æ ¼å¼ä¸ºJSONï¼š
            [
                {{
                    "title": "æ–°é—»æ ‡é¢˜",
                    "content": "æ–°é—»å†…å®¹æ‘˜è¦",
                    "source": "æ–°é—»æ¥æº",
                    "time": "å‘å¸ƒæ—¶é—´",
                    "url": "æ–°é—»é“¾æ¥ï¼ˆå¦‚æœæœ‰ï¼‰"
                }}
            ]
            """
            
            response = model.generate_content(prompt)
            result_text = response.text
            
            try:
                start_idx = result_text.find('[')
                end_idx = result_text.rfind(']') + 1
                if start_idx != -1 and end_idx != -1:
                    json_text = result_text[start_idx:end_idx]
                    news_data = json.loads(json_text)
                    all_news.extend(news_data)
                    log(f"âœ… Gemini æœç´¢æˆåŠŸ: {len(news_data)} æ¡æ–°é—»")
                else:
                    log("âš ï¸ Gemini è¿”å›æ ¼å¼å¼‚å¸¸")
            except json.JSONDecodeError as e:
                log(f"âš ï¸ JSON è§£æå¤±è´¥: {e}")
            
            time.sleep(2)  # é¿å… API é™åˆ¶
            
        except Exception as e:
            log(f"âŒ Gemini æœç´¢å¤±è´¥: {e}")
    
    return all_news

def categorize_news(news_items):
    """å¯¹æ–°é—»è¿›è¡Œåˆ†ç±»"""
    categories = {
        'congress_bills': [],  # å›½ä¼šææ¡ˆ
        'trade_policy': [],    # è´¸æ˜“æ”¿ç­–
        'technology': [],      # æŠ€æœ¯é™åˆ¶
        'taiwan': [],          # å°æ¹¾é—®é¢˜
        'military': [],        # å†›äº‹å¤–äº¤
        'other': []            # å…¶ä»–
    }
    
    for news in news_items:
        title = news.get('title', '').lower()
        content = news.get('content', '').lower()
        text = f"{title} {content}"
        
        if any(word in text for word in ['congress', 'senate', 'house', 'bill', 'proposal', 'legislation', 'committee']):
            categories['congress_bills'].append(news)
        elif any(word in text for word in ['trade', 'tariff', 'import', 'export', 'commerce', 'economic']):
            categories['trade_policy'].append(news)
        elif any(word in text for word in ['technology', 'semiconductor', 'chip', 'ai', 'artificial intelligence', '5g', 'cyber', 'huawei', 'tiktok']):
            categories['technology'].append(news)
        elif any(word in text for word in ['taiwan', 'taiwanese', 'tsai', 'cross-strait']):
            categories['taiwan'].append(news)
        elif any(word in text for word in ['military', 'defense', 'navy', 'air force', 'pacific', 'south china sea']):
            categories['military'].append(news)
        else:
            categories['other'].append(news)
    
    return categories

def send_telegram_message(bot_token, chat_id, text):
    """å‘é€ Telegram æ¶ˆæ¯"""
    log("ğŸ“¤ å‘é€ Telegram æ¶ˆæ¯...")
    
    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
    payload = {
        'chat_id': chat_id,
        'text': text,
        'parse_mode': 'HTML',
        'disable_web_page_preview': True
    }
    
    try:
        log(f"æ¶ˆæ¯é•¿åº¦: {len(text)} å­—ç¬¦")
        response = requests.post(url, json=payload, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            if result.get('ok'):
                log("âœ… Telegram æ¶ˆæ¯å‘é€æˆåŠŸ")
                return True
            else:
                log(f"âŒ Telegram API é”™è¯¯: {result.get('description')}")
                return False
        else:
            log(f"âŒ HTTP é”™è¯¯: {response.status_code}")
            return False
            
    except Exception as e:
        log(f"âŒ å‘é€å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    log("ğŸš€ ä¸­ç¾å…³ç³»ä¸“é¢˜æ–°é—» Bot å¯åŠ¨")
    log("=" * 50)
    
    try:
        # 1. æ£€æŸ¥ç¯å¢ƒå˜é‡
        log("ğŸ“‹ æ£€æŸ¥ç¯å¢ƒå˜é‡...")
        bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
        chat_id = os.getenv('CHAT_ID')
        
        if not bot_token or not chat_id:
            log("âŒ ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡")
            sys.exit(1)
        
        log("âœ… ç¯å¢ƒå˜é‡æ£€æŸ¥é€šè¿‡")
        
        # 2. è®¾ç½® Gemini API
        model = setup_gemini()
        
        # 3. è·å–ä¸­ç¾å…³ç³»æ–°é—»
        all_news = []
        
        # GNews API
        gnews_key = os.getenv('GNEWS_API_KEY')
        if gnews_key:
            gnews_items = fetch_gnews_china_us(gnews_key, 8)
            all_news.extend(gnews_items)
        
        # RSS æ–°é—»
        rss_items = fetch_rss_china_us()
        all_news.extend(rss_items)
        
        # Gemini æœç´¢
        if model:
            gemini_items = search_china_us_with_gemini(model)
            all_news.extend(gemini_items)
        
        # å»é‡
        seen_titles = set()
        unique_news = []
        for news in all_news:
            title = news.get('title', '').lower()
            if title not in seen_titles and len(title) > 10:
                seen_titles.add(title)
                unique_news.append(news)
        
        # åˆ†ç±»
        categories = categorize_news(unique_news)
        
        # 4. æ ¼å¼åŒ–æ¶ˆæ¯
        timestamp = get_beijing_timestamp()
        
        if unique_news:
            message_lines = []
            message_lines.append("ğŸ‡ºğŸ‡¸ğŸ‡¨ğŸ‡³ ä¸­ç¾å…³ç³»ä¸“é¢˜ç®€æŠ¥")
            message_lines.append("")
            message_lines.append(f"ğŸ“… æ›´æ–°æ—¶é—´: {timestamp} (UTC+8)")
            message_lines.append(f"ğŸ“Š ä»Šæ—¥æ”¶é›† {len(unique_news)} æ¡ä¸­ç¾å…³ç³»æ–°é—»")
            message_lines.append("")
            
            # æŒ‰ç±»åˆ«æ˜¾ç¤ºæ–°é—»
            category_names = {
                'congress_bills': 'ğŸ›ï¸ å›½ä¼šææ¡ˆä¸ç«‹æ³•',
                'trade_policy': 'ğŸ’° è´¸æ˜“æ”¿ç­–',
                'technology': 'ğŸ”¬ æŠ€æœ¯é™åˆ¶',
                'taiwan': 'ğŸï¸ å°æ¹¾é—®é¢˜',
                'military': 'âš”ï¸ å†›äº‹å¤–äº¤',
                'other': 'ğŸ“° å…¶ä»–è¦é—»'
            }
            
            for category, name in category_names.items():
                items = categories[category]
                if items:
                    message_lines.append(f"<b>{name}</b>")
                    
                    for i, news in enumerate(items[:3], 1):  # æ¯ç±»æœ€å¤š3æ¡
                        title = news.get('title', 'æ— æ ‡é¢˜')
                        content = news.get('content', '')
                        source = news.get('source', 'æœªçŸ¥æ¥æº')
                        url = news.get('url', '')
                        
                        # ç¿»è¯‘æ ‡é¢˜ä¸æ‘˜è¦
                        zh_title = translate_with_gemini(model, title) if model else title
                        summary = summarize_text(model, title, content)
                        zh_title = clean_ai_artifacts(sanitize_text(zh_title))
                        summary = clean_ai_artifacts(sanitize_text(summary))
                        zh_title = escape_html(zh_title)
                        summary = escape_html(summary)
                        
                        if len(zh_title) > 80:
                            zh_title = zh_title[:77] + "..."
                        
                        if url:
                            message_lines.append(f"{i}ï¸âƒ£ <a href=\"{escape_html(url)}\">{zh_title}</a>")
                        else:
                            message_lines.append(f"{i}ï¸âƒ£ {zh_title}")
                        if summary:
                            message_lines.append(f"ğŸ“ æ‘˜è¦: {summary}")
                        message_lines.append(f"ğŸ“° æ¥æº: {escape_html(sanitize_text(source))}")
                        message_lines.append("")
            
            message_lines.append("ğŸ“ æ¥æºï¼šå¤šå®¶æƒå¨åª’ä½“ + AI æ‘˜è¦")
            message_text = "\n".join(message_lines)
            
            # å®‰å…¨é•¿åº¦æ§åˆ¶
            if len(message_text) > 4000:
                message_text = message_text[:3997] + "..."
            message = message_text
        else:
            message = f"""ğŸ‡ºğŸ‡¸ğŸ‡¨ğŸ‡³ ä¸­ç¾å…³ç³»ä¸“é¢˜ç®€æŠ¥

ğŸ“… æ›´æ–°æ—¶é—´: {timestamp} (UTC+8)

âš ï¸ ä»Šæ—¥ä¸­ç¾å…³ç³»æ–°é—»æºæš‚æ—¶ä¸å¯ç”¨
ğŸ¤– è¯·ç¨åæŸ¥çœ‹æ–°é—»ç½‘ç«™è·å–æœ€æ–°èµ„è®¯

ğŸ’¡ æˆ‘ä»¬æ­£åœ¨åŠªåŠ›æ¢å¤æœåŠ¡..."""
        
        # 5. å‘é€æ¶ˆæ¯
        success = send_telegram_message(bot_token, chat_id, message)
        
        if success:
            log("ğŸ‰ ä»»åŠ¡å®Œæˆ! æ¶ˆæ¯å·²æˆåŠŸå‘é€åˆ° Telegram")
        else:
            log("âŒ ä»»åŠ¡å¤±è´¥! æ¶ˆæ¯å‘é€å¤±è´¥")
            sys.exit(1)
            
    except Exception as e:
        log(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
